{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ccdaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from array import array\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm, trange\n",
    "import scipy.io\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d5fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", dpi=100)\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "plt.rc('font', size=SMALL_SIZE)\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55171576",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f16d44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_templates_path = '/Users/ankit/Documents/PaninskiLab/contrastive_spikes/DY016/'\n",
    "temp_file = 'kilosort_cleaned_templates.npy'\n",
    "good_unit_file = 'good_units_kilosort.npy'\n",
    "\n",
    "kilo_temps = np.load(dy_templates_path + temp_file)\n",
    "good_units = np.load(dy_templates_path + good_unit_file)\n",
    "kilo_good = kilo_temps[good_units]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f497ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcs = np.array([np.abs(wf).max(0).argmax() for wf in kilo_temps])\n",
    "align_ts = np.asarray([np.abs(wf[:, mc]).argmax() for (wf, mc) in zip(kilo_temps, mcs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8270cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_max_channels = np.array([np.argmax(np.max(template, axis=0) - np.min(template, axis=0)) for template in kilo_temps])\n",
    "max_peak_inds = np.array([np.argmax(template, axis=0) for template in kilo_temps])\n",
    "max_chan_templates = np.array([kilo_temps[i].T[unit_max_channels[i]] for i in range(len(unit_max_channels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec38a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak to peak computations to get the max \n",
    "ptps = np.array([np.max(template.max(0) - template.min(0)) for template in kilo_temps])\n",
    "high_ptp_indices = np.array([i for i in range(len(kilo_temps)) if ptps[i] > 5])\n",
    "high_ptp_temps = kilo_temps[high_ptp_indices]\n",
    "max_chan_hptp_temps = max_chan_templates[high_ptp_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7b5825",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_interest_dy = [8, 9, 11, 33, 65, 69, 109, 13, 329, 151]\n",
    "wf_dy_idx = [0, 1, 2, 10, 22, 25, 38, 3, 50, 102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b464ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_wfs_interest = np.load('/Users/ankit/Documents/PaninskiLab/contrastive_spikes/DY016/spikes_train.npy')\n",
    "dy_wfs_test = np.load('/Users/ankit/Documents/PaninskiLab/contrastive_spikes/DY016/spikes_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "810ede8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_wfs = np.load('/Users/ankit/Documents/PaninskiLab/contrastive_spikes/DY016/kilosort_cleaned_templates.npy')\n",
    "unit_ids = np.load('/Users/ankit/Documents/PaninskiLab/contrastive_spikes/DY016/unit_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d599c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(482, 121)\n",
      "(118, 121)\n"
     ]
    }
   ],
   "source": [
    "dy_wfs = np.transpose(dy_wfs, (0, 2, 1))[np.arange(dy_wfs.shape[0]), mcs]\n",
    "print(dy_wfs.shape)\n",
    "\n",
    "dy_wfs_sel = dy_wfs[unit_ids]\n",
    "print(dy_wfs_sel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b0ee5",
   "metadata": {},
   "source": [
    "## Contrastive Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f936b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# Model definition\n",
    "class SingleChanDenoiser(nn.Module):\n",
    "    \"\"\"Cleaned up a little. Why is conv3 here and commented out in forward?\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, n_filters=[16, 8, 4], filter_sizes=[5, 11, 21], spike_size=121, out_size=2\n",
    "    ):\n",
    "        super(SingleChanDenoiser, self).__init__()\n",
    "        feat1, feat2, feat3 = n_filters\n",
    "        size1, size2, size3 = filter_sizes\n",
    "        print(out_size)\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(1, feat1, size1), nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(feat1, feat2, size2), nn.ReLU())\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(feat2, feat3, size3), nn.ReLU())\n",
    "        n_input_feat = feat2 * (spike_size - size1 - size2 + 2)\n",
    "        self.fc = nn.Linear(n_input_feat, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, None]\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # x = self.conv3(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "    def load(self, fname_model):\n",
    "        checkpoint = torch.load(fname_model, map_location=\"cpu\")\n",
    "        state_dict = checkpoint[\"state_dict\"]\n",
    "        new_state_dict = OrderedDict()\n",
    "        for key in state_dict:\n",
    "            if \"backbone\" in key and \"fc\" not in key:\n",
    "                new_key = '.'.join(key.split('.')[1:])\n",
    "                new_state_dict[new_key] = state_dict[key]\n",
    "        new_state_dict[\"fc.weight\"] = state_dict[\"backbone.fc.2.weight\"]\n",
    "        new_state_dict[\"fc.bias\"] = state_dict[\"backbone.fc.2.bias\"]\n",
    "        self.load_state_dict(new_state_dict)\n",
    "        return self\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, Lv=[200, 150, 100, 75], ks=[11, 21, 31], out_size=2, proj_dim=5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.proj_dim = out_size if out_size < proj_dim else proj_dim\n",
    "        self.enc_block1d = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=Lv[0], kernel_size=ks[0], padding=math.ceil((ks[0]-1)/2)),\n",
    "            nn.BatchNorm1d(Lv[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            # nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(Lv[0], Lv[1], ks[1], padding=math.ceil((ks[1]-1)/2)),\n",
    "            nn.BatchNorm1d(Lv[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            # nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(Lv[1], Lv[2], ks[2], padding=math.ceil((ks[2]-1)/2)),\n",
    "            nn.BatchNorm1d(Lv[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4)\n",
    "        )\n",
    "        self.avgpool1d = nn.AdaptiveAvgPool1d((1))\n",
    "\n",
    "        self.fcpart = nn.Sequential(\n",
    "            nn.Linear(Lv[2] * 1 * 1, Lv[3]),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(p=0.2),\n",
    "            nn.Linear(Lv[3], out_size),\n",
    "            Projector(rep_dim=out_size, proj_dim=self.proj_dim)\n",
    "            )\n",
    "        self.Lv = Lv\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc_block1d(x)\n",
    "        x = self.avgpool1d(x)\n",
    "        x = x.view(-1, self.Lv[2] * 1 * 1)\n",
    "        x = self.fcpart(x)\n",
    "        return x\n",
    "\n",
    "    def load(self, fname_model):\n",
    "        checkpoint = torch.load(fname_model, map_location=\"cpu\")\n",
    "        state_dict = checkpoint[\"state_dict\"]\n",
    "        new_state_dict = OrderedDict()\n",
    "        for key in state_dict:\n",
    "            # if \"backbone\" in key and \"fc\" not in key:\n",
    "            new_key = '.'.join(key.split('.')[1:])\n",
    "            new_state_dict[new_key] = state_dict[key]\n",
    "        self.load_state_dict(new_state_dict)\n",
    "        return self\n",
    "    \n",
    "\n",
    "class Encoder2(nn.Module):\n",
    "    def __init__(self, Lv=[64, 128, 256, 256, 256], ks=[11], out_size = 2, proj_dim=5, fc_depth=2):\n",
    "        super(Encoder2, self).__init__()\n",
    "        self.proj_dim = out_size if out_size < proj_dim else proj_dim\n",
    "        self.enc_block1d = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=Lv[0], kernel_size=ks[0], padding=math.ceil((ks[0]-1)/2)),\n",
    "            nn.BatchNorm1d(Lv[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            # nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(Lv[0], Lv[1], ks[0], padding=math.ceil((ks[0]-1)/2)),\n",
    "            nn.BatchNorm1d(Lv[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            # nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(Lv[1], Lv[2], ks[0], padding=math.ceil((ks[0]-1)/2)),\n",
    "            nn.BatchNorm1d(Lv[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Conv1d(Lv[2], Lv[3], ks[0], padding=math.ceil((ks[0]-1)/2)),\n",
    "            nn.BatchNorm1d(Lv[2]),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.avgpool1d = nn.AdaptiveAvgPool1d((1))\n",
    "        list_layers = [nn.Linear(Lv[3] * 1 * 1, Lv[4]), nn.ReLU(inplace=True)]\n",
    "        for _ in range(fc_depth-2):\n",
    "            list_layers += [nn.Linear(Lv[4], Lv[4]), nn.ReLU(inplace=True)]\n",
    "        list_layers += [nn.Linear(Lv[4], out_size), nn.ReLU(inplace=True)]\n",
    "        list_layers += [Projector(rep_dim=out_size, proj_dim=self.proj_dim)]\n",
    "        \n",
    "        self.fcpart = nn.Sequential(*list_layers)\n",
    "        \n",
    "        # nn.Sequential(\n",
    "        #     nn.Linear(Lv[2] * 1 * 1, Lv[3]),\n",
    "        #     nn.ReLU(),\n",
    "        #     # nn.Dropout(p=0.2),\n",
    "        #     nn.Linear(Lv[3], out_size),\n",
    "        #     )\n",
    "        self.Lv = Lv\n",
    "        # self.projector = Projector2(rep_dim=out_size, proj_dim=self.proj_dim)\n",
    "    def forward(self, x):\n",
    "        x = self.enc_block1d(x)\n",
    "        # print(x.shape)\n",
    "        x = self.avgpool1d(x)\n",
    "        x = x.view(-1, self.Lv[2] * 1 * 1)\n",
    "        x = self.fcpart(x)\n",
    "        # x = self.projector(x)\n",
    "        return x\n",
    "    \n",
    "    def load(self, fname_model):\n",
    "        checkpoint = torch.load(fname_model, map_location=\"cpu\")\n",
    "        state_dict = checkpoint[\"state_dict\"]\n",
    "        new_state_dict = OrderedDict()\n",
    "        for key in state_dict:\n",
    "            # if \"backbone\" in key and \"fc\" not in key:\n",
    "            new_key = '.'.join(key.split('.')[1:])\n",
    "            new_state_dict[new_key] = state_dict[key]\n",
    "            if 'pos_encoder' in key:\n",
    "                new_state_dict[key] = state_dict[key].transpose()\n",
    "        self.load_state_dict(new_state_dict)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "    \n",
    "class AttentionEnc(nn.Module):\n",
    "    def __init__(self, spike_size=121, n_channels=1, out_size=2, proj_dim=5, fc_depth=2, nlayers=9, nhead=8, dropout=0.1, expand_dim=16):\n",
    "        super(AttentionEnc, self).__init__()\n",
    "        self.spike_size = spike_size\n",
    "        self.expand_dim = expand_dim\n",
    "        self.proj_dim = out_size if out_size < proj_dim else proj_dim\n",
    "        if expand_dim != 1:\n",
    "            self.encoder = nn.Linear(n_channels, expand_dim)\n",
    "        else:\n",
    "            nhead = 1\n",
    "        self.pos_encoder = PositionalEncoding(expand_dim, dropout, spike_size)\n",
    "        encoder_layers = TransformerEncoderLayer(expand_dim, nhead, 512, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        list_layers = [nn.Linear(self.spike_size * expand_dim, 256), nn.ReLU(inplace=True)]\n",
    "        for _ in range(fc_depth-2):\n",
    "            list_layers += [nn.Linear(256, 256), nn.ReLU(inplace=True)]\n",
    "        list_layers += [nn.Linear(256, out_size)]\n",
    "        list_layers += [Projector(rep_dim=out_size, proj_dim=self.proj_dim)]\n",
    "        \n",
    "        self.fcpart = nn.Sequential(*list_layers)\n",
    "        \n",
    "        # self.fcpart = nn.Sequential(\n",
    "        #     nn.Linear(self.spike_size * expand_dim, self.spike_size),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(self.spike_size, out_size),\n",
    "            \n",
    "        #     # nn.ReLU(),\n",
    "        #     # nn.Dropout(p=0.2),\n",
    "        #     # nn.Linear(5 * self.spike_size * expand_dim, out_size),\n",
    "        #     Projector(rep_dim=out_size, proj_dim=self.proj_dim)\n",
    "        # )\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        # self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fcpart.bias.data.zero_()\n",
    "        self.fpcart.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [batch_size, seq_len]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "        Returns:\n",
    "            output Tensor of shape [batch_size, proj_dim]\n",
    "        \"\"\"\n",
    "        src = torch.transpose(src, 1, 2)\n",
    "        if self.expand_dim != 1:\n",
    "            src = self.encoder(src) * math.sqrt(self.expand_dim)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = output.view(-1, self.spike_size * self.expand_dim)\n",
    "        output = self.fcpart(output)\n",
    "        return output\n",
    "\n",
    "    def load(self, fname_model):\n",
    "        checkpoint = torch.load(fname_model, map_location=\"cpu\")\n",
    "        state_dict = checkpoint[\"state_dict\"]\n",
    "        new_state_dict = OrderedDict()\n",
    "        for key in state_dict:\n",
    "            # if \"backbone\" in key and \"fc\" not in key:\n",
    "            new_key = '.'.join(key.split('.')[1:])\n",
    "            new_state_dict[new_key] = state_dict[key]\n",
    "            if 'pos_encoder' in key:\n",
    "                new_state_dict[new_key] = state_dict[key].transpose(0, 1)\n",
    "        self.load_state_dict(new_state_dict)\n",
    "        return self\n",
    "    \n",
    "class FullyConnectedEnc(nn.Module):\n",
    "    def __init__(self, Lv=[121, 550, 1100, 250], out_size=2, proj_dim=5):\n",
    "        super(FullyConnectedEnc, self).__init__()\n",
    "        self.proj_dim = out_size if out_size < proj_dim else proj_dim\n",
    "\n",
    "        self.fcpart = nn.Sequential(\n",
    "            nn.Linear(Lv[0], Lv[1]),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(p=0.2),\n",
    "            nn.Linear(Lv[1], Lv[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(Lv[2], Lv[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(Lv[3], out_size),\n",
    "            Projector(rep_dim=out_size, proj_dim=self.proj_dim)\n",
    "            )\n",
    "        self.Lv = Lv\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fcpart(x)\n",
    "        return x\n",
    "\n",
    "    def load(self, fname_model):\n",
    "        checkpoint = torch.load(fname_model, map_location=\"cpu\")\n",
    "        state_dict = checkpoint[\"state_dict\"]\n",
    "        new_state_dict = OrderedDict()\n",
    "        for key in state_dict:\n",
    "            # if \"backbone\" in key and \"fc\" not in key:\n",
    "            new_key = '.'.join(key.split('.')[1:])\n",
    "            new_state_dict[new_key] = state_dict[key]\n",
    "        self.load_state_dict(new_state_dict)\n",
    "        return self\n",
    "\n",
    "class Projector(nn.Module):\n",
    "    ''' Projector network accepts a variable number of layers indicated by depth.\n",
    "    Option to include batchnorm after every layer.'''\n",
    "\n",
    "    def __init__(self, Lvpj=[512, 128], rep_dim=5, proj_dim=5, bnorm = False, depth = 3):\n",
    "        super(Projector, self).__init__()\n",
    "        print(f\"Using projector; batchnorm {bnorm} with depth {depth}; hidden_dim={Lvpj[0]}\")\n",
    "        nlayer = [nn.BatchNorm1d(Lvpj[0])] if bnorm else []\n",
    "        list_layers = [nn.Linear(rep_dim, Lvpj[0])] + nlayer + [nn.ReLU()]\n",
    "        for _ in range(depth-2):\n",
    "            list_layers += [nn.Linear(Lvpj[0], Lvpj[0])] + nlayer + [nn.ReLU()]\n",
    "        list_layers += [nn.Linear(Lvpj[0], proj_dim)]\n",
    "        self.proj_block = nn.Sequential(*list_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj_block(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2034b4bd",
   "metadata": {},
   "source": [
    "## Functions to Compute and Plot Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "734f7498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import umap.umap_ as umap\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# def learn_manifold_umap(data, umap_dim, umap_min_dist=0.2, umap_metric='euclidean', umap_neighbors=10):\n",
    "#     md = float(umap_min_dist)\n",
    "#     return umap.UMAP(random_state=0, metric=umap_metric, n_components=umap_dim, n_neighbors=umap_neighbors,\n",
    "#                     min_dist=md).fit_transform(data)\n",
    "\n",
    "def pca_train(train, test, n_comps):\n",
    "    pca_ = PCA(n_components=n_comps)\n",
    "    pca_.fit(train)\n",
    "    print('train done')\n",
    "    test_comps = pca_.transform(test)\n",
    "    print('pca test done')\n",
    "    return test_comps, pca_.explained_variance_ratio_\n",
    "\n",
    "def pca(S, n_comps):\n",
    "    pca_ = PCA(n_components=n_comps)\n",
    "    return pca_.fit_transform(S), pca_.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d2abae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run templates through model to get contrastive representations\n",
    "def compute_reps(model, og_temps, tform_temps):\n",
    "    og_reps = []\n",
    "    tform_reps = []\n",
    "    model = model.double()\n",
    "    for i, og_temp in enumerate(og_temps):\n",
    "        tf_temp = tform_temps[i][None, :]\n",
    "        with torch.no_grad():\n",
    "            og_rep = model(torch.from_numpy(og_temp.reshape(1, -1)).double())\n",
    "            tf_rep = model(tf_temp.double())\n",
    "        og_reps.append(og_rep.numpy())\n",
    "        tform_reps.append(tf_rep.numpy())\n",
    "    \n",
    "    return np.squeeze(np.array(og_reps)), np.squeeze(np.array(tform_reps))\n",
    "\n",
    "# Run templates through model to get contrastive representations\n",
    "def compute_reps_test(model, test_wfs):\n",
    "    og_reps = []\n",
    "    model = model.double()\n",
    "    for i, og_temp in enumerate(test_wfs):\n",
    "        with torch.no_grad():\n",
    "            og_rep = model(torch.from_numpy(og_temp.reshape(1, 1, -1)).double())\n",
    "        og_reps.append(og_rep.numpy())\n",
    "    \n",
    "    return np.squeeze(np.array(og_reps))\n",
    "\n",
    "\n",
    "# plot representations of a few templates along with the templates themselves\n",
    "def plot_reps(og_temps, tform_temps, og_reps, tform_reps, title=None, save_name=None):\n",
    "    n_temps = len(og_temps)\n",
    "    lat_dim = og_reps.shape[1]\n",
    "    num_sels = 6 if lat_dim > 2 else 4\n",
    "    temp_sels = np.random.choice(np.arange(n_temps), num_sels)\n",
    "    \n",
    "    max_chan_max = [max(np.max(og_temps[temp_sels[i]]), np.max(tform_temps[temp_sels[i]].numpy())) for i in range(0, num_sels)]\n",
    "    max_chan_min = [min(np.min(og_temps[temp_sels[i]]), np.min(tform_temps[temp_sels[i]].numpy())) for i in range(0, num_sels)]\n",
    "    # max_chan_max = max([np.max(temp) for temp in tot_temps])\n",
    "    # max_chan_min = min([np.min(temp) for temp in tot_temps])\n",
    "    colors = ['blue', 'red', 'green', 'yellow', 'orange', 'black'] if lat_dim > 2 else ['blue', 'red', 'green', 'yellow']\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 8), constrained_layout=True) if lat_dim > 2 else plt.figure(figsize=(12, 4), constrained_layout=True)\n",
    "    gs = GridSpec(4, 6, figure=fig) if lat_dim > 2 else GridSpec(2, 6, figure=fig)\n",
    "    \n",
    "    ax0 = fig.add_subplot(gs[2:, :3]) if lat_dim > 2 else fig.add_subplot(gs[:2, :2])\n",
    "    ax0.scatter(og_reps[temp_sels, 0], og_reps[temp_sels, 1], c=colors, clip_on=False)\n",
    "    ax0.scatter(tform_reps[temp_sels, 0], tform_reps[temp_sels, 1], c=colors, clip_on=False)\n",
    "    pnt_names = ['wf {}'.format(str(temp_sels[i])) for i in range(num_sels)] + ['augmented wf {}'.format(str(temp_sels[i])) for i in range(num_sels)] \n",
    "    \n",
    "    if og_reps.shape[1] > 2:\n",
    "        ax1 = fig.add_subplot(gs[2:, 4:], projection='3d')\n",
    "        ax1.scatter(og_reps[temp_sels, 2], og_reps[temp_sels, 3], og_reps[temp_sels, 4], c=colors, clip_on=False)\n",
    "        ax1.scatter(tform_reps[temp_sels, 2], tform_reps[temp_sels, 3], tform_reps[temp_sels, 3], c=colors, clip_on=False) \n",
    "    \n",
    "    for i, txt in enumerate(pnt_names):\n",
    "        if i < num_sels:\n",
    "            ax0.annotate(txt, (og_reps[temp_sels, 0][i], og_reps[temp_sels, 1][i]))\n",
    "            if og_reps.shape[1] > 2:\n",
    "                ax1.text(og_reps[temp_sels, 2][i], og_reps[temp_sels, 3][i], og_reps[temp_sels, 4][i], txt)\n",
    "        else:\n",
    "            ax0.annotate(txt, (tform_reps[temp_sels, 0][i-num_sels], tform_reps[temp_sels, 1][i-num_sels]))\n",
    "            if og_reps.shape[1] > 2:\n",
    "                ax1.text(tform_reps[temp_sels, 2][i-num_sels], og_reps[temp_sels, 3][i-num_sels], og_reps[temp_sels, 4][i-num_sels], txt)\n",
    "    \n",
    "    if lat_dim > 2:\n",
    "        axs = [fig.add_subplot(gs[0, i]) for i in range(num_sels)] + [fig.add_subplot(gs[1, i]) for i in range(num_sels)]\n",
    "    else:\n",
    "        axs = [fig.add_subplot(gs[0, i]) for i in range(2, 2+num_sels)] + [fig.add_subplot(gs[1, i]) for i in range(2, 2+num_sels)]\n",
    "        \n",
    "    x = np.arange(0, 121)\n",
    "\n",
    "    for i in range(num_sels):\n",
    "        # axs[0] = fig.add_subplot(gs[i//2, 2 + 2*(i%2)])\n",
    "        axs[2*i].set_ylim(max_chan_min[i]-0.5, max_chan_max[i]+0.5)\n",
    "        axs[2*i].title.set_text('wf {}'.format(str(temp_sels[i])))\n",
    "        axs[2*i].plot(x, og_temps[temp_sels[i]], linewidth=2, markersize=12, color=colors[i])\n",
    "        axs[2*i].get_xaxis().set_visible(False)\n",
    "\n",
    "        # ax2 = fig.add_subplot(gs[i//2, 3 + 2*(i%2)])\n",
    "        axs[2*i+1].title.set_text('augmented wf {}'.format(str(temp_sels[i])))\n",
    "        axs[2*i+1].set_ylim(max_chan_min[i]-0.5, max_chan_max[i]+0.5)\n",
    "        axs[2*i+1].plot(x, tform_temps[temp_sels[i]].numpy(), linewidth=2, markersize=12, color=colors[i])\n",
    "        axs[2*i+1].get_xaxis().set_visible(False)\n",
    "    \n",
    "    # fig.subplots_adjust(wspace=0)\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    if save_name is not None:\n",
    "        plt.savefig(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5d7a97",
   "metadata": {},
   "source": [
    "### MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9343b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    '''\n",
    "        Multilayer Perceptron.\n",
    "    '''\n",
    "    def __init__(self, input_size=2, layer_sizes=[100, 50, 10]):\n",
    "        super().__init__()\n",
    "        if len(layer_sizes) == 3:\n",
    "            self.layers = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(input_size, layer_sizes[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_sizes[0], layer_sizes[1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_sizes[1], layer_sizes[2])\n",
    "            )\n",
    "        else:\n",
    "            self.layers = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(input_size, layer_sizes[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(layer_sizes[0], layer_sizes[1])\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        return self.layers(x)\n",
    "    \n",
    "def train(data, labels, layers=[1000, 50, 10], epochs=25):\n",
    "    mlp = MLP(input_size=data.shape[1], layer_sizes=layers)\n",
    "    train_data = list(zip(data, labels))\n",
    "    trainloader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "  \n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop\n",
    "    for epoch in range(epochs): # 5 epochs at maximum\n",
    "\n",
    "        # Print epoch\n",
    "        # if epoch % (epochs//10):\n",
    "        #     print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "        # Set current loss value\n",
    "        current_loss = 0.0\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(trainloader):\n",
    "\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Perform forward pass\n",
    "            outputs = mlp(inputs.float())\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_function(outputs, targets)\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            current_loss += loss.item()\n",
    "\n",
    "            # if i % 500 == 499:\n",
    "            #     print('Loss after mini-batch %5d: %.3f' %\n",
    "            #         (i + 1, current_loss / 500))\n",
    "            #     current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished.')\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb785f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def class_scores(train_reps, test_reps, num_classes, layers=[1000, 100, 10], epochs=100):\n",
    "    labels_train = np.array([[i for j in range(1200)] for i in range(num_classes)]).reshape(-1)\n",
    "    labels_test = np.array([[i for j in range(300)] for i in range(num_classes)]).reshape(-1)\n",
    "    \n",
    "    # knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "    # knn.fit(train_reps, labels_train)\n",
    "    mlp = train(train_reps, labels_train, layers, epochs=epochs)\n",
    "    per_class_acc = {}\n",
    "    for i in range(num_classes):\n",
    "        # class_score = knn.score(test_reps[300*i:300*(i+1)], labels_test[300*i:300*(i+1)])*100\n",
    "        with torch.no_grad():\n",
    "            pred_labels = np.argmax(mlp(torch.from_numpy(test_reps[300*i:300*(i+1)]).float()).numpy(), axis=1)\n",
    "        class_score = accuracy_score(labels_test[300*i:300*(i+1)], pred_labels) * 100\n",
    "        per_class_acc['wf {}'.format(str(wf_interest_dy[i]))] = class_score\n",
    "    return per_class_acc\n",
    "        \n",
    "def avg_score(train_reps, test_reps, num_classes, layers=[1000, 100, 10], epochs=100):\n",
    "    labels_train = np.array([[i for j in range(1200)] for i in range(num_classes)]).reshape(-1)\n",
    "    labels_test = np.array([[i for j in range(300)] for i in range(num_classes)]).reshape(-1)\n",
    "    \n",
    "    # knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "    # knn.fit(train_reps, labels_train)\n",
    "    # acc['score'] = knn.score(test_reps, labels_test)*100\n",
    "    \n",
    "    mlp = train(train_reps, labels_train, layers, epochs=100)\n",
    "    with torch.no_grad():\n",
    "        pred_labels = np.argmax(mlp(torch.from_numpy(test_reps).float()).numpy(), axis=1)\n",
    "    acc = {}\n",
    "    acc['score'] = accuracy_score(pred_labels, labels_test)*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e226cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_accs(train_reps, test_reps, models, num_classes):\n",
    "    class_res = {}\n",
    "\n",
    "    for i in range(len(train_reps)):\n",
    "        class_res[models[i]] = class_scores(train_reps[i], test_reps[i], num_classes)\n",
    "        \n",
    "    return class_res\n",
    "\n",
    "def avg_class_accs(train_reps, test_reps, models, num_classes):\n",
    "    class_res = {}\n",
    "\n",
    "    for i in range(len(train_reps)):\n",
    "        class_res[models[i]] = avg_score(train_reps[i], test_reps[i], num_classes)\n",
    "        \n",
    "    return class_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5de2243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enc_backbone(enc):\n",
    "    last_layer = list(list(enc.children())[-1].children())[:-1]\n",
    "    enc.fcpart = nn.Sequential(*last_layer)\n",
    "    return enc\n",
    "\n",
    "def get_fcenc_backbone(enc):\n",
    "    last_layer = list(list(enc.children())[-1].children())[:-1]\n",
    "    enc.fcpart = nn.Sequential(*last_layer)\n",
    "    return enc\n",
    "\n",
    "def get_ckpt_results(ckpt, lat_dim, train_data, test_data, plot=False, wfs=None, wfs_interest=None, title=None, enc_type=None, Lv=None, ks=None, fc=None, save_name=None):\n",
    "    if enc_type is None or enc_type == 'encoder':\n",
    "        Lv = [200, 150, 100, 75] if Lv is None else Lv\n",
    "        ks = [11, 21, 31] if ks is None else ks\n",
    "        enc = Encoder(Lv=Lv, ks=ks, out_size=lat_dim).load(ckpt)\n",
    "        backbone = get_enc_backbone(enc)\n",
    "    elif enc_type == 'fc_encoder':\n",
    "        Lv = [121, 550, 1100, 250] if Lv is None else Lv\n",
    "        enc = FullyConnectedEnc(Lv=Lv, out_size=lat_dim).load(ckpt)\n",
    "        backbone = get_fcenc_backbone(enc)\n",
    "    elif enc_type == 'custom_encoder2':\n",
    "        Lv=[64, 128, 256, 256, 256] if Lv is None else Lv\n",
    "        ks = [11] if ks is None else ks\n",
    "        enc = Encoder2(Lv=Lv, ks=ks, out_size=lat_dim).load(ckpt)\n",
    "        backbone = get_enc_backbone(enc)\n",
    "    elif enc_type == 'attention_encoder':\n",
    "        fc_depth = 2 if fc is None else fc\n",
    "        enc = AttentionEnc(out_size=lat_dim, proj_dim=5, fc_depth=fc_depth, dropout=0.1, expand_dim=16).load(ckpt)\n",
    "        backbone = get_fcenc_backbone(enc)\n",
    "        \n",
    "    contr_reps_train = compute_reps_test(backbone, train_data)\n",
    "    contr_reps_test = compute_reps_test(backbone, test_data)\n",
    "\n",
    "    if lat_dim > 2:\n",
    "        # contr_reps_test_umap = learn_manifold_umap(contr_reps_test, 2) \n",
    "        contr_reps_test_pca, _ = pca(contr_reps_test, 2)\n",
    "    else:\n",
    "        contr_reps_test_pca = contr_reps_test\n",
    "\n",
    "    pca_tr, _ = pca(train_data, lat_dim)\n",
    "    pca_test, _ = pca_train(train_data, test_data, lat_dim)\n",
    "    \n",
    "    if plot:\n",
    "        plot_contr_v_pca(pca_test, contr_reps_test_pca, wfs, wfs_interest, title=title, save_name=save_name)\n",
    "    \n",
    "    return contr_reps_train, contr_reps_test, contr_reps_test_pca, pca_tr, pca_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1754b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contr_v_pca(pca_reps, contr_reps, wfs, wf_interest, title=None, save_name=None, wf_selection=None):\n",
    "    og_wfs = wfs[wf_interest]\n",
    "    n_temps = len(pca_reps)\n",
    "    lat_dim = pca_reps.shape[1]\n",
    "    num_wfs = len(og_wfs)\n",
    "    \n",
    "    max_chan_max = np.max(np.max(og_wfs, axis=1))\n",
    "    max_chan_min = np.min(np.min(og_wfs, axis=1))\n",
    "    # max_chan_max = max([np.max(temp) for temp in tot_temps])\n",
    "    # max_chan_min = min([np.min(temp) for temp in tot_temps])\n",
    "    if wf_selection is None:\n",
    "        colors = ['blue', 'red', 'green', 'yellow', 'orange', 'black', 'cyan', 'violet', 'maroon', 'pink'][:num_wfs]\n",
    "    else:\n",
    "        colors = ['blue', 'red', 'green', 'yellow', 'orange', 'black', 'cyan', 'violet', 'maroon', 'pink'][wf_selection[0]:wf_selection[1]]\n",
    "        print(colors)\n",
    "    num_reps = int(len(pca_reps) / num_wfs)\n",
    "    print(num_reps)\n",
    "    labels = np.array([[colors[i] for j in range(num_reps)] for i in range(num_wfs)])\n",
    "    labels = labels.flatten()\n",
    "    print(labels.shape)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 8), constrained_layout=True)\n",
    "    gs = GridSpec(4, num_wfs, figure=fig)\n",
    "    \n",
    "    ax0 = fig.add_subplot(gs[:3, :int(num_wfs/2)])\n",
    "    ax0.title.set_text('PCA wf representations')\n",
    "    ax0.scatter(pca_reps[:, 0], pca_reps[:, 1], c=labels, clip_on=False)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[:3, int(num_wfs/2):])\n",
    "    ax1.title.set_text('Contrastive wf representations')\n",
    "    ax1.scatter(contr_reps[:, 0], contr_reps[:, 1], c=labels, clip_on=True) \n",
    "    # ax1.set_xlim([0, 25])\n",
    "    # ax1.set_ylim([-7, 15])\n",
    "    \n",
    "    axs = [fig.add_subplot(gs[3, i]) for i in range(num_wfs)]\n",
    "        \n",
    "    x = np.arange(0, 121)\n",
    "\n",
    "    for i in range(num_wfs):\n",
    "        # axs[0] = fig.add_subplot(gs[i//2, 2 + 2*(i%2)])\n",
    "        axs[i].set_ylim(max_chan_min-0.5, max_chan_max+0.5)\n",
    "        axs[i].title.set_text('unit {}'.format(str(wf_interest[i])))\n",
    "        axs[i].plot(x, og_wfs[i], linewidth=2, markersize=12, color=colors[i])\n",
    "        axs[i].get_xaxis().set_visible(False)\n",
    "    \n",
    "    # fig.subplots_adjust(wspace=0)\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    if save_name is not None:\n",
    "        plt.savefig(save_name)\n",
    "        \n",
    "def plot_recon_v_spike(wf_train, wf_test, wfs, wf_interest, ckpt, lat_dim, title, save_name=None, wf_selection=None):\n",
    "    og_wfs = wfs[wf_interest]\n",
    "    tot_spikes, n_times = wf_test.shape\n",
    "    spike_sel = np.random.choice(tot_spikes)\n",
    "    spike = wf_test[spike_sel]\n",
    "    num_wfs = 10\n",
    "    \n",
    "    pca_aug = PCA_Reproj()\n",
    "    pca_train = np.array([pca_aug(wf) for wf in wf_train])\n",
    "    pca_test = np.array([pca_aug(wf) for wf in wf_test])\n",
    "    \n",
    "    _, contr_spikes_test, contr_spikes_test_pca, _, pca_spikes_test = get_ckpt_results(ckpt, lat_dim, wf_train, wf_test)\n",
    "    # contr_spikes_test_pca = contr_spikes_test_pca.reshape(4, num_ex, -1)\n",
    "    # pca_spikes_test = pca_spikes_test.reshape(4, num_ex, -1)\n",
    "    \n",
    "    _, contr_recon_test, contr_recon_test_pca, _, pca_recon_test = get_ckpt_results(ckpt, lat_dim, pca_train, pca_test)\n",
    "    # contr_recon_test_pca = contr_recon_test_pca.reshape(4, num_ex, -1)\n",
    "    # pca_spikes_test = pca_spikes_test.reshape(4, num_ex, -1)\n",
    "    \n",
    "    max_chan_max = np.max(np.max(og_wfs, axis=1))\n",
    "    max_chan_min = np.min(np.min(og_wfs, axis=1))\n",
    "    # max_chan_max = max([np.max(temp) for temp in tot_temps])\n",
    "    # max_chan_min = min([np.min(temp) for temp in tot_temps])\n",
    "    if wf_selection is None:\n",
    "        colors = ['blue', 'red', 'green', 'yellow', 'orange', 'black', 'cyan', 'violet', 'maroon', 'pink'][:num_wfs]\n",
    "    else:\n",
    "        colors = ['blue', 'red', 'green', 'yellow', 'orange', 'black', 'cyan', 'violet', 'maroon', 'pink'][wf_selection[0]:wf_selection[1]]\n",
    "        print(colors)\n",
    "    num_reps = int(len(wf_test) / num_wfs)\n",
    "    print(num_reps)\n",
    "    labels = np.array([[colors[i] for j in range(num_reps)] for i in range(num_wfs)])\n",
    "    labels = labels.flatten()\n",
    "    print(labels.shape)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 8), constrained_layout=True)\n",
    "    gs = GridSpec(4, num_wfs, figure=fig)\n",
    "    \n",
    "    ax0 = fig.add_subplot(gs[:3, :int(num_wfs/2)])\n",
    "    ax0.title.set_text('Contrastive spike representations')\n",
    "    ax0.scatter(contr_spikes_test_pca[:, 0], contr_spikes_test_pca[:, 1], c=labels, clip_on=False)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[:3, int(num_wfs/2):])\n",
    "    ax1.title.set_text('Contrastive pca recon. spike representations')\n",
    "    ax1.scatter(contr_recon_test_pca[:, 0], contr_recon_test_pca[:, 1], c=labels, clip_on=True) \n",
    "    # ax1.set_xlim([0, 25])\n",
    "    # ax1.set_ylim([-7, 15])\n",
    "    \n",
    "    axs = [fig.add_subplot(gs[3, i]) for i in range(num_wfs)]\n",
    "        \n",
    "    x = np.arange(0, 121)\n",
    "\n",
    "    for i in range(num_wfs):\n",
    "        # axs[0] = fig.add_subplot(gs[i//2, 2 + 2*(i%2)])\n",
    "        axs[i].set_ylim(max_chan_min-0.5, max_chan_max+0.5)\n",
    "        axs[i].title.set_text('unit {}'.format(str(wf_interest[i])))\n",
    "        axs[i].plot(x, og_wfs[i], linewidth=2, markersize=12, color=colors[i])\n",
    "        axs[i].get_xaxis().set_visible(False)\n",
    "    \n",
    "    # fig.subplots_adjust(wspace=0)\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    if save_name is not None:\n",
    "        plt.savefig(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a40fe5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aug_shifts(wf_train, wf_test, ckpt, lat_dim, title, save_name=None):\n",
    "    tot_spikes, n_times = wf_test.shape\n",
    "    spike_sel = np.random.choice(tot_spikes)\n",
    "    spike = wf_test[spike_sel]\n",
    "    num_ex = 10\n",
    "    \n",
    "    jit = Jitter()\n",
    "    collide = Collide()\n",
    "    noise = SmartNoise()\n",
    "    \n",
    "    amp_jitter_spikes = np.array([scale * spike for scale in np.linspace(0.9, 1.1, num=num_ex)])\n",
    "    jitter_spikes = np.array([jit(spike) for i in range(num_ex)])\n",
    "    collided_spikes = np.array([collide(spike) for i in range(num_ex)])\n",
    "    noised_spikes = np.array([noise(spike) for i in range(num_ex)])\n",
    "    aug_spikes = np.array([amp_jitter_spikes, jitter_spikes, collided_spikes, noised_spikes])\n",
    "    aug_titles = ['Amplitude Jitter', 'Jitter', 'Collision', 'Noise']\n",
    "\n",
    "    _, contr_reps_test, contr_reps_test_pca, _, pca_test = get_ckpt_results(ckpt, lat_dim, wf_train, aug_spikes.reshape(-1, 121))\n",
    "    contr_reps_test_pca = contr_reps_test_pca.reshape(4, num_ex, -1)\n",
    "    pca_test = pca_test.reshape(4, num_ex, -1)\n",
    "    \n",
    "#     sel_spikes = np.array([max_chan_spikes[i, sels[i], :] for i in range(num_temps)])\n",
    "    \n",
    "#     max_chan_max = [np.max([np.max(sel_spikes[i][j] for j in range(num_sel_spikes))]) for i in range(num_temps)]\n",
    "#     print(max_chan_max)\n",
    "#     max_chan_min = [np.min([np.min(sel_spikes[i][j] for j in range(num_sel_spikes))]) for i in range(num_temps)]\n",
    "    # max_chan_max = max([np.max(temp) for temp in tot_temps])\n",
    "    # max_chan_min = min([np.min(temp) for temp in tot_temps])\n",
    "    colors = ['blue', 'red', 'green', 'magenta']\n",
    "    # cmap = plt.cm.get_cmap('hsv', 10)\n",
    "    # colors = [cmap(i) for i in range(10)]\n",
    "    alphas = np.linspace(0.1, 1, num=10)\n",
    "    SMALL_SIZE = 12\n",
    "    MEDIUM_SIZE = 16\n",
    "    BIGGER_SIZE = 20\n",
    "    plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    # fig, ax = plt.subplots(4, 6, figsize=(18, 30))\n",
    "    fig = plt.figure(figsize=(22, 18), constrained_layout=True)\n",
    "    fig.tight_layout()\n",
    "    gs = GridSpec(8, 9, figure=fig)\n",
    "    \n",
    "    for row in range(8):\n",
    "        \n",
    "        zero_title = '{}'.format(aug_titles[row//2])\n",
    "        \n",
    "        x = np.arange(0, n_times)\n",
    "        ax0 = fig.add_subplot(gs[row, 0])\n",
    "        if row % 2 == 0:\n",
    "            ax0.title.set_text(zero_title)\n",
    "        ax0.plot(x, aug_spikes[row//2, (row%2)*5 + 0], linewidth=2, markersize=12, color=colors[row//2], alpha=alphas[(row%2)*5 + 0])\n",
    "        # ax0.plot(x, aug_spikes[row//2, (row%2)*5 + 0], linewidth=2, markersize=12, color=colors[(row%2)*5 + 0])\n",
    "        ax0.get_xaxis().set_visible(False)\n",
    "        # ax0.get_yaxis().set_visible(False)\n",
    "        \n",
    "        # print(max_chan_min[row] + ' ')\n",
    "        # print(max_chan_max[row])\n",
    "        # ax[row, 0].set_ylim(max_chan_min[row]-0.5, max_chan_max[row]+0.5)\n",
    "        ax1 = fig.add_subplot(gs[row, 1], sharey=ax0)\n",
    "        ax1.plot(x, aug_spikes[row//2, (row%2)*5 + 1], linewidth=2, markersize=12, color=colors[row//2], alpha=alphas[(row%2)*5 + 1])\n",
    "        # ax1.plot(x, aug_spikes[row//2, (row%2)*5 + 1], linewidth=2, markersize=12, color=colors[(row%2)*5 + 1])\n",
    "        ax1.get_xaxis().set_visible(False)\n",
    "        ax1.get_yaxis().set_visible(False)\n",
    "\n",
    "        # ax[row, 1].title.set_text('view 1')\n",
    "        ax2 = fig.add_subplot(gs[row, 2], sharey=ax0)\n",
    "        ax2.plot(x, aug_spikes[row//2, (row%2)*5 + 2], linewidth=2, markersize=12, color=colors[row//2], alpha=alphas[(row%2)*5 + 2])\n",
    "        # ax2.plot(x, aug_spikes[row//2, (row%2)*5 + 2], linewidth=2, markersize=12, color=colors[(row%2)*5 + 2])\n",
    "        ax2.get_xaxis().set_visible(False)\n",
    "        ax2.get_yaxis().set_visible(False)\n",
    "        \n",
    "        # ax[row, 2].title.set_text('view 2')\n",
    "        ax3 = fig.add_subplot(gs[row, 3], sharey=ax0)\n",
    "        ax3.plot(x, aug_spikes[row//2, (row%2)*5 + 3], linewidth=2, markersize=12, color=colors[row//2], alpha=alphas[(row%2)*5 + 3])\n",
    "        # ax3.plot(x, aug_spikes[row//2, (row%2)*5 + 3], linewidth=2, markersize=12, color=colors[(row%2)*5 + 3])\n",
    "        ax3.get_xaxis().set_visible(False)\n",
    "        ax3.get_yaxis().set_visible(False)\n",
    "\n",
    "        # ax[row, 3].title.set_text('overlaid view 1')\n",
    "        ax4 = fig.add_subplot(gs[row, 4], sharey=ax0)\n",
    "        ax4.plot(x, aug_spikes[row//2, (row%2)*5 + 4], linewidth=2, markersize=12, color=colors[row//2], alpha=alphas[(row%2)*5 + 4])\n",
    "        # ax4.plot(x, aug_spikes[row//2, (row%2)*5 + 4], linewidth=2, markersize=12, color=colors[(row%2)*5 + 4])\n",
    "        ax4.get_xaxis().set_visible(False)\n",
    "        ax4.get_yaxis().set_visible(False)\n",
    "        \n",
    "        if row % 2 == 0:\n",
    "            ax5 = fig.add_subplot(gs[row:row+2, 5:7])\n",
    "            if row == 0:\n",
    "                ax5.title.set_text('Contrastive 2D PCA Representations')\n",
    "            ax5.scatter(contr_reps_test_pca[row//2, :, 0], contr_reps_test_pca[row//2, :, 1], color=colors[row//2], alpha=alphas)\n",
    "            # ax5.scatter(contr_reps_test_pca[row//2, :, 0], contr_reps_test_pca[row//2, :, 1], color=colors)\n",
    "            # ax[row, 5].get_xaxis().set_visible(False)\n",
    "            ax5.set_xlim([-1, 1])\n",
    "            ax5.set_ylim([-1, 1])\n",
    "            \n",
    "        if row % 2 == 0:\n",
    "            ax6 = fig.add_subplot(gs[row:row+2, 7:])\n",
    "            if row == 0:\n",
    "                ax6.title.set_text('PCA 2D Representations')\n",
    "            ax6.scatter(pca_test[row//2, :, 0], pca_test[row//2, :, 1], color=colors[row//2], alpha=alphas)\n",
    "            # ax5.scatter(contr_reps_test_pca[row//2, :, 0], contr_reps_test_pca[row//2, :, 1], color=colors)\n",
    "            # ax[row, 5].get_xaxis().set_visible(False)\n",
    "            ax6.set_xlim([-25, 25])\n",
    "            ax6.set_ylim([-20, 20])\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    fig.subplots_adjust(top=0.94)\n",
    "    # fig.subplots_adjust(wspace=0.12)\n",
    "    \n",
    "    fig.subplots_adjust(hspace=0.4)\n",
    "    \n",
    "    if save_name is not None:\n",
    "        plt.savefig(save_name)\n",
    "        \n",
    "\n",
    "def plot_recon_v_spikes_indiv(wf_train, wf_test, ckpt, lat_dim, pca_dim, title, enc_type=None, Lv=None, ks=None, save_name=None):\n",
    "    tot_spikes, n_times = wf_test.shape\n",
    "    spike_sels = np.array([15 + 300*ind for ind in range(10)])\n",
    "    spikes = wf_test[spike_sels]\n",
    "    num_ex = 10\n",
    "    \n",
    "    pca_aug = PCA_Reproj(pca_dim=pca_dim)\n",
    "    pca_train = np.array([pca_aug(wf) for wf in wf_train])\n",
    "    pca_test = np.array([pca_aug(wf) for wf in wf_test])\n",
    "\n",
    "    _, contr_spikes_test, contr_spikes_test_pca, _, pca_spikes_test = get_ckpt_results(ckpt, lat_dim, wf_train, wf_test, enc_type=enc_type, Lv=Lv, ks=ks)\n",
    "    print(contr_spikes_test_pca.shape)\n",
    "    contr_spikes_test_pca = contr_spikes_test_pca[spike_sels]\n",
    "    pca_spikes_test = pca_spikes_test[spike_sels]\n",
    "    \n",
    "    _, contr_recon_test, contr_recon_test_pca, _, pca_recon_test = get_ckpt_results(ckpt, lat_dim, pca_train, pca_test, enc_type=enc_type, Lv=Lv, ks=ks)\n",
    "    contr_recon_test_pca = contr_recon_test_pca[spike_sels]\n",
    "    pca_recon_test = pca_recon_test[spike_sels]\n",
    "    \n",
    "#     colors = ['blue', 'red', 'green', 'magenta']\n",
    "#     cmap = plt.cm.get_cmap('hsv', 10)\n",
    "#     colors = [cmap(i) for i in range(10)]\n",
    "    colors = ['blue', 'red', 'green', 'yellow', 'orange', 'black', 'cyan', 'violet', 'maroon', 'pink']\n",
    "#     alphas = np.linspace(0.1, 1, num=10)\n",
    "    alphas = np.ones(10)\n",
    "    SMALL_SIZE = 12\n",
    "    MEDIUM_SIZE = 16\n",
    "    BIGGER_SIZE = 20\n",
    "    plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    # fig, ax = plt.subplots(4, 6, figsize=(18, 30))\n",
    "    fig = plt.figure(figsize=(22, 5), constrained_layout=True)\n",
    "    fig.tight_layout()\n",
    "    gs = GridSpec(2, 9, figure=fig)\n",
    "\n",
    "    for row in range(2):\n",
    "        \n",
    "#         zero_title = '{}'.format(aug_titles[row//2])\n",
    "        \n",
    "        x = np.arange(0, n_times)\n",
    "        ax0 = fig.add_subplot(gs[row, 0])\n",
    "#         if row % 2 == 0:\n",
    "#             ax0.title.set_text(zero_title)\n",
    "        ax0.plot(x, spikes[(row%2)*5 + 0], linewidth=2, markersize=12, color=colors[5*row], alpha=alphas[(row%2)*5 + 0])\n",
    "        # ax0.plot(x, aug_spikes[row//2, (row%2)*5 + 0], linewidth=2, markersize=12, color=colors[(row%2)*5 + 0])\n",
    "        ax0.get_xaxis().set_visible(False)\n",
    "        # ax0.get_yaxis().set_visible(False)\n",
    "        \n",
    "        # print(max_chan_min[row] + ' ')\n",
    "        # print(max_chan_max[row])\n",
    "        # ax[row, 0].set_ylim(max_chan_min[row]-0.5, max_chan_max[row]+0.5)\n",
    "        ax1 = fig.add_subplot(gs[row, 1], sharey=ax0)\n",
    "        ax1.plot(x, spikes[(row%2)*5 + 1], linewidth=2, markersize=12, color=colors[5*row+1], alpha=alphas[(row%2)*5 + 1])\n",
    "        # ax1.plot(x, aug_spikes[row//2, (row%2)*5 + 1], linewidth=2, markersize=12, color=colors[(row%2)*5 + 1])\n",
    "        ax1.get_xaxis().set_visible(False)\n",
    "        ax1.get_yaxis().set_visible(False)\n",
    "\n",
    "        # ax[row, 1].title.set_text('view 1')\n",
    "        ax2 = fig.add_subplot(gs[row, 2], sharey=ax0)\n",
    "        ax2.plot(x, spikes[(row%2)*5 + 2], linewidth=2, markersize=12, color=colors[5*row+2], alpha=alphas[(row%2)*5 + 2])\n",
    "        # ax2.plot(x, aug_spikes[row//2, (row%2)*5 + 2], linewidth=2, markersize=12, color=colors[(row%2)*5 + 2])\n",
    "        ax2.get_xaxis().set_visible(False)\n",
    "        ax2.get_yaxis().set_visible(False)\n",
    "        \n",
    "        # ax[row, 2].title.set_text('view 2')\n",
    "        ax3 = fig.add_subplot(gs[row, 3], sharey=ax0)\n",
    "        ax3.plot(x, spikes[(row%2)*5 + 3], linewidth=2, markersize=12, color=colors[5*row+3], alpha=alphas[(row%2)*5 + 3])\n",
    "        # ax3.plot(x, aug_spikes[row//2, (row%2)*5 + 3], linewidth=2, markersize=12, color=colors[(row%2)*5 + 3])\n",
    "        ax3.get_xaxis().set_visible(False)\n",
    "        ax3.get_yaxis().set_visible(False)\n",
    "\n",
    "        # ax[row, 3].title.set_text('overlaid view 1')\n",
    "        ax4 = fig.add_subplot(gs[row, 4], sharey=ax0)\n",
    "        ax4.plot(x, spikes[(row%2)*5 + 4], linewidth=2, markersize=12, color=colors[5*row+4], alpha=alphas[(row%2)*5 + 4])\n",
    "        # ax4.plot(x, aug_spikes[row//2, (row%2)*5 + 4], linewidth=2, markersize=12, color=colors[(row%2)*5 + 4])\n",
    "        ax4.get_xaxis().set_visible(False)\n",
    "        ax4.get_yaxis().set_visible(False)\n",
    "        \n",
    "        if row % 2 == 0:\n",
    "            ax5 = fig.add_subplot(gs[row:row+2, 5:7])\n",
    "            if row == 0:\n",
    "                ax5.title.set_text('Contrastive Representations')\n",
    "            ax5.scatter(contr_spikes_test_pca[:, 0], contr_spikes_test_pca[:, 1], color=colors, alpha=alphas, label='spike')\n",
    "            ax5.scatter(contr_recon_test_pca[:, 0], contr_recon_test_pca[:, 1], color=colors, alpha=alphas, marker='x', label='recon. spike')\n",
    "            # ax5.scatter(contr_reps_test_pca[row//2, :, 0], contr_reps_test_pca[row//2, :, 1], color=colors)\n",
    "            # ax[row, 5].get_xaxis().set_visible(False)\n",
    "#             ax5.set_xlim([-1, 1])\n",
    "#             ax5.set_ylim([-1, 1])\n",
    "            ax5.legend()\n",
    "            \n",
    "            ax6 = fig.add_subplot(gs[row:row+2, 7:])\n",
    "            if row == 0:\n",
    "                ax6.title.set_text('PCA Representations')\n",
    "            ax6.scatter(pca_spikes_test[:, 0], pca_spikes_test[:, 1], color=colors, alpha=alphas, label='spike')\n",
    "            ax6.scatter(pca_recon_test[:, 0], pca_recon_test[:, 1], color=colors, alpha=alphas, marker='x', label='recon. spike')\n",
    "            # ax5.scatter(contr_reps_test_pca[row//2, :, 0], contr_reps_test_pca[row//2, :, 1], color=colors)\n",
    "            # ax[row, 5].get_xaxis().set_visible(False)\n",
    "            ax6.set_xlim([-25, 25])\n",
    "            ax6.set_ylim([-20, 20])\n",
    "            ax6.legend()\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    # fig.subplots_adjust(wspace=0.12)\n",
    "    \n",
    "    fig.subplots_adjust(hspace=0.2)\n",
    "    \n",
    "    if save_name is not None:\n",
    "        plt.savefig(save_name)\n",
    "\n",
    "        \n",
    "def plot_recon_v_spikes_indiv_pca(wf_train, wf_test, ckpt, lat_dim, pca_dim, title, save_name=None):\n",
    "    tot_spikes, n_times = wf_test.shape\n",
    "    spike_sels = np.array([15 + 300*ind for ind in range(10)])\n",
    "    spikes = wf_test[spike_sels]\n",
    "    num_ex = 10\n",
    "    \n",
    "    pca_aug = PCA_Reproj(pca_dim=pca_dim)\n",
    "    pca_train = np.array([pca_aug(wf) for wf in wf_train])\n",
    "    pca_test = np.array([pca_aug(wf) for wf in wf_test])\n",
    "\n",
    "    _, contr_spikes_test, contr_spikes_test_pca, _, pca_spikes_test = get_ckpt_results(ckpt, lat_dim, wf_train, wf_test)\n",
    "    pca_spikes_test = pca_spikes_test[spike_sels]\n",
    "    \n",
    "    _, contr_recon_test, contr_recon_test_pca, _, pca_recon_test = get_ckpt_results(ckpt, lat_dim, pca_train, pca_test)\n",
    "    pca_recon_test = pca_recon_test[spike_sels]\n",
    "    \n",
    "#     colors = ['blue', 'red', 'green', 'magenta']\n",
    "#     cmap = plt.cm.get_cmap('hsv', 10)\n",
    "#     colors = [cmap(i) for i in range(10)]\n",
    "    colors = ['blue', 'red', 'green', 'yellow', 'orange', 'black', 'cyan', 'violet', 'maroon', 'pink']\n",
    "#     alphas = np.linspace(0.1, 1, num=10)\n",
    "    alphas = np.ones(10)\n",
    "    SMALL_SIZE = 12\n",
    "    MEDIUM_SIZE = 16\n",
    "    BIGGER_SIZE = 20\n",
    "    plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    \n",
    "    # fig, ax = plt.subplots(4, 6, figsize=(18, 30))\n",
    "    fig = plt.figure(figsize=(17, 5), constrained_layout=True)\n",
    "    fig.tight_layout()\n",
    "    gs = GridSpec(2, 7, figure=fig)\n",
    "\n",
    "    for row in range(2):\n",
    "        \n",
    "#         zero_title = '{}'.format(aug_titles[row//2])\n",
    "        \n",
    "        x = np.arange(0, n_times)\n",
    "        ax0 = fig.add_subplot(gs[row, 0])\n",
    "#         if row % 2 == 0:\n",
    "#             ax0.title.set_text(zero_title)\n",
    "        ax0.plot(x, spikes[(row%2)*5 + 0], linewidth=2, markersize=12, color=colors[5*row], alpha=alphas[(row%2)*5 + 0])\n",
    "        # ax0.plot(x, aug_spikes[row//2, (row%2)*5 + 0], linewidth=2, markersize=12, color=colors[(row%2)*5 + 0])\n",
    "        ax0.get_xaxis().set_visible(False)\n",
    "        # ax0.get_yaxis().set_visible(False)\n",
    "        \n",
    "        # print(max_chan_min[row] + ' ')\n",
    "        # print(max_chan_max[row])\n",
    "        # ax[row, 0].set_ylim(max_chan_min[row]-0.5, max_chan_max[row]+0.5)\n",
    "        ax1 = fig.add_subplot(gs[row, 1], sharey=ax0)\n",
    "        ax1.plot(x, spikes[(row%2)*5 + 1], linewidth=2, markersize=12, color=colors[5*row+1], alpha=alphas[(row%2)*5 + 1])\n",
    "        # ax1.plot(x, aug_spikes[row//2, (row%2)*5 + 1], linewidth=2, markersize=12, color=colors[(row%2)*5 + 1])\n",
    "        ax1.get_xaxis().set_visible(False)\n",
    "        ax1.get_yaxis().set_visible(False)\n",
    "\n",
    "        # ax[row, 1].title.set_text('view 1')\n",
    "        ax2 = fig.add_subplot(gs[row, 2], sharey=ax0)\n",
    "        ax2.plot(x, spikes[(row%2)*5 + 2], linewidth=2, markersize=12, color=colors[5*row+2], alpha=alphas[(row%2)*5 + 2])\n",
    "        # ax2.plot(x, aug_spikes[row//2, (row%2)*5 + 2], linewidth=2, markersize=12, color=colors[(row%2)*5 + 2])\n",
    "        ax2.get_xaxis().set_visible(False)\n",
    "        ax2.get_yaxis().set_visible(False)\n",
    "        \n",
    "        # ax[row, 2].title.set_text('view 2')\n",
    "        ax3 = fig.add_subplot(gs[row, 3], sharey=ax0)\n",
    "        ax3.plot(x, spikes[(row%2)*5 + 3], linewidth=2, markersize=12, color=colors[5*row+3], alpha=alphas[(row%2)*5 + 3])\n",
    "        # ax3.plot(x, aug_spikes[row//2, (row%2)*5 + 3], linewidth=2, markersize=12, color=colors[(row%2)*5 + 3])\n",
    "        ax3.get_xaxis().set_visible(False)\n",
    "        ax3.get_yaxis().set_visible(False)\n",
    "\n",
    "        # ax[row, 3].title.set_text('overlaid view 1')\n",
    "        ax4 = fig.add_subplot(gs[row, 4], sharey=ax0)\n",
    "        ax4.plot(x, spikes[(row%2)*5 + 4], linewidth=2, markersize=12, color=colors[5*row+4], alpha=alphas[(row%2)*5 + 4])\n",
    "        # ax4.plot(x, aug_spikes[row//2, (row%2)*5 + 4], linewidth=2, markersize=12, color=colors[(row%2)*5 + 4])\n",
    "        ax4.get_xaxis().set_visible(False)\n",
    "        ax4.get_yaxis().set_visible(False)\n",
    "        \n",
    "        if row % 2 == 0:\n",
    "            ax5 = fig.add_subplot(gs[row:row+2, 5:7])\n",
    "            if row == 0:\n",
    "                ax5.title.set_text('2D Spike v. Reconstructed Spike Representations')\n",
    "            ax5.scatter(pca_spikes_test[:, 0], pca_spikes_test[:, 1], color=colors, alpha=alphas, label='spike')\n",
    "            ax5.scatter(pca_recon_test[:, 0], pca_recon_test[:, 1], color=colors, alpha=alphas, marker='x', label='recon. spike')\n",
    "            # ax5.scatter(contr_reps_test_pca[row//2, :, 0], contr_reps_test_pca[row//2, :, 1], color=colors)\n",
    "            # ax[row, 5].get_xaxis().set_visible(False)\n",
    "            ax5.set_xlim([-25, 25])\n",
    "            ax5.set_ylim([-20, 20])\n",
    "            ax5.legend()\n",
    "            \n",
    "#         if row % 2 == 0:\n",
    "#             ax6 = fig.add_subplot(gs[row:row+2, 7:])\n",
    "#             if row == 0:\n",
    "#                 ax6.title.set_text('2D Reconstructed Spike Representations')\n",
    "#             ax6.scatter(contr_recon_test_pca[:, 0], contr_recon_test_pca[:, 1], color=colors, alpha=alphas)\n",
    "#             # ax5.scatter(contr_reps_test_pca[row//2, :, 0], contr_reps_test_pca[row//2, :, 1], color=colors)\n",
    "#             # ax[row, 5].get_xaxis().set_visible(False)\n",
    "#             ax6.set_xlim([-1, 1])\n",
    "#             ax6.set_ylim([-1, 1])\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    # fig.subplots_adjust(wspace=0.12)\n",
    "    \n",
    "    fig.subplots_adjust(hspace=0.2)\n",
    "    \n",
    "    if save_name is not None:\n",
    "        plt.savefig(save_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdecb32",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbf0544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using projector; batchnorm False with depth 3; hidden_dim=512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m fived_norm_attenc001_sgd_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/ankit/Documents/PaninskiLab/SimCLR-torch/runs/new_augs/spike_att_tb/attenc-5d5d-lr001-sgd/checkpoint_0500.pth.tar\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m fived_norm_attenc001_sgdfc4_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/ankit/Documents/PaninskiLab/SimCLR-torch/runs/new_augs/spike_att_tb/attenc-5d5d-lr001-sgd-fc4/checkpoint_0500.pth.tar\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m contr_reps_train_5d_att001, contr_reps_test_5d_att001, contr_reps_test_5d_pca_att001, pca_train_5d, pca_test_5d \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mget_ckpt_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfived_norm_attenc001_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdy_wfs_interest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdy_wfs_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdy_wfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwfs_interest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwf_interest_dy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m5D contrastive model (augs=a/j/n, transformer, lr=0.001) (2D PCA reps) - test set\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                     \u001b[49m\u001b[43menc_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_encoder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msave_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpca_v_5dcont_normal_attenc_lr001\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m contr_reps_train_5d_att0001_fc4, contr_reps_test_5d_att0001_fc4, contr_reps_test_5d_pca_att0001_fc4, _, _ \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     17\u001b[0m     get_ckpt_results(fived_norm_attenc0001_fc4_path, \u001b[38;5;241m5\u001b[39m, dy_wfs_interest, dy_wfs_test, \u001b[38;5;28;01mTrue\u001b[39;00m, dy_wfs, wf_interest_dy, \\\n\u001b[1;32m     18\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5D contrastive model (augs=a/j/n, transformer, lr=0.0001, fc4) (2D PCA reps) - test set\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[1;32m     19\u001b[0m                      enc_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_encoder\u001b[39m\u001b[38;5;124m'\u001b[39m, fc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, \\\n\u001b[1;32m     20\u001b[0m                      save_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpca_v_5dcont_normal_attenc_lr0001fc4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m contr_reps_train_5d_att0001, contr_reps_test_5d_att0001, contr_reps_test_5d_pca_att0001, _, _ \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     22\u001b[0m     get_ckpt_results(fived_norm_attenc0001_path, \u001b[38;5;241m5\u001b[39m, dy_wfs_interest, dy_wfs_test, \u001b[38;5;28;01mTrue\u001b[39;00m, dy_wfs, wf_interest_dy, \\\n\u001b[1;32m     23\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5D contrastive model (augs=a/j/n, transformer, lr=0.0001) (2D PCA reps) - test set\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[1;32m     24\u001b[0m                      enc_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_encoder\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[1;32m     25\u001b[0m                      save_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpca_v_5dcont_normal_attenc_lr0001\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36mget_ckpt_results\u001b[0;34m(ckpt, lat_dim, train_data, test_data, plot, wfs, wfs_interest, title, enc_type, Lv, ks, fc, save_name)\u001b[0m\n\u001b[1;32m     28\u001b[0m     enc \u001b[38;5;241m=\u001b[39m AttentionEnc(out_size\u001b[38;5;241m=\u001b[39mlat_dim, proj_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, fc_depth\u001b[38;5;241m=\u001b[39mfc_depth, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, expand_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\u001b[38;5;241m.\u001b[39mload(ckpt)\n\u001b[1;32m     29\u001b[0m     backbone \u001b[38;5;241m=\u001b[39m get_fcenc_backbone(enc)\n\u001b[0;32m---> 31\u001b[0m contr_reps_train \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_reps_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m contr_reps_test \u001b[38;5;241m=\u001b[39m compute_reps_test(backbone, test_data)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lat_dim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# contr_reps_test_umap = learn_manifold_umap(contr_reps_test, 2) \u001b[39;00m\n",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36mcompute_reps_test\u001b[0;34m(model, test_wfs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, og_temp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_wfs):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 22\u001b[0m         og_rep \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mog_temp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     og_reps\u001b[38;5;241m.\u001b[39mappend(og_rep\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqueeze(np\u001b[38;5;241m.\u001b[39marray(og_reps))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mAttentionEnc.forward\u001b[0;34m(self, src, src_mask)\u001b[0m\n\u001b[1;32m    228\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_dim)\n\u001b[1;32m    229\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src)\n\u001b[0;32m--> 230\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspike_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_dim)\n\u001b[1;32m    232\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfcpart(output)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/torch/nn/modules/transformer.py:280\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    277\u001b[0m         src_key_padding_mask_for_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 280\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    283\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/torch/nn/modules/transformer.py:538\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    536\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 538\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    539\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/torch/nn/modules/transformer.py:546\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    545\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 546\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/torch/nn/modules/activation.py:1167\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1157\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         q_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj_weight, k_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj_weight,\n\u001b[1;32m   1165\u001b[0m         v_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj_weight, average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights)\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/torch/nn/functional.py:5163\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[1;32m   5161\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m softmax(attn_output_weights, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   5162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout_p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m-> 5163\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5165\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(attn_output_weights, v)\n\u001b[1;32m   5167\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(tgt_len \u001b[38;5;241m*\u001b[39m bsz, embed_dim)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fived_norm_attenc001_path = '/Users/ankit/Documents/PaninskiLab/SimCLR-torch/runs/new_augs/spike_att_tb/attenc-5d5d-lr001/checkpoint_0500.pth.tar'\n",
    "fived_norm_attenc0001_fc4_path = '/Users/ankit/Documents/PaninskiLab/SimCLR-torch/runs/new_augs/spike_att_tb/attenc-5d5d-lr0001-fc4/checkpoint_0500.pth.tar'\n",
    "fived_norm_attenc0001_path = '/Users/ankit/Documents/PaninskiLab/SimCLR-torch/runs/new_augs/spike_att_tb/attenc-5d5d-lr0001/checkpoint_0500.pth.tar'\n",
    "fived_norm_attenc01_sgd_path = '/Users/ankit/Documents/PaninskiLab/SimCLR-torch/runs/new_augs/spike_att_tb/attenc-5d5d-lr01-sgd/checkpoint_0500.pth.tar'\n",
    "fived_norm_attenc01_sgdfc4_path = '/Users/ankit/Documents/PaninskiLab/SimCLR-torch/runs/new_augs/spike_att_tb/attenc-5d5d-lr01-sgd-fc4/checkpoint_0500.pth.tar'\n",
    "fived_norm_attenc001_sgd_path = '/Users/ankit/Documents/PaninskiLab/SimCLR-torch/runs/new_augs/spike_att_tb/attenc-5d5d-lr001-sgd/checkpoint_0500.pth.tar'\n",
    "fived_norm_attenc001_sgdfc4_path = '/Users/ankit/Documents/PaninskiLab/SimCLR-torch/runs/new_augs/spike_att_tb/attenc-5d5d-lr001-sgd-fc4/checkpoint_0500.pth.tar'\n",
    "\n",
    "\n",
    "contr_reps_train_5d_att001, contr_reps_test_5d_att001, contr_reps_test_5d_pca_att001, pca_train_5d, pca_test_5d = \\\n",
    "    get_ckpt_results(ckpt=fived_norm_attenc001_path, lat_dim=5, train_data=dy_wfs_interest, test_data=dy_wfs_test, \\\n",
    "                     plot=True, wfs=dy_wfs, wfs_interest=wf_interest_dy, \\\n",
    "                     title='5D contrastive model (augs=a/j/n, transformer, lr=0.001) (2D PCA reps) - test set', \\\n",
    "                     enc_type='attention_encoder', \\\n",
    "                     save_name='pca_v_5dcont_normal_attenc_lr001')\n",
    "contr_reps_train_5d_att0001_fc4, contr_reps_test_5d_att0001_fc4, contr_reps_test_5d_pca_att0001_fc4, _, _ = \\\n",
    "    get_ckpt_results(fived_norm_attenc0001_fc4_path, 5, dy_wfs_interest, dy_wfs_test, True, dy_wfs, wf_interest_dy, \\\n",
    "                     '5D contrastive model (augs=a/j/n, transformer, lr=0.0001, fc4) (2D PCA reps) - test set', \\\n",
    "                     enc_type='attention_encoder', fc=4, \\\n",
    "                     save_name='pca_v_5dcont_normal_attenc_lr0001fc4')\n",
    "contr_reps_train_5d_att0001, contr_reps_test_5d_att0001, contr_reps_test_5d_pca_att0001, _, _ = \\\n",
    "    get_ckpt_results(fived_norm_attenc0001_path, 5, dy_wfs_interest, dy_wfs_test, True, dy_wfs, wf_interest_dy, \\\n",
    "                     '5D contrastive model (augs=a/j/n, transformer, lr=0.0001) (2D PCA reps) - test set', \\\n",
    "                     enc_type='attention_encoder', \\\n",
    "                     save_name='pca_v_5dcont_normal_attenc_lr0001')\n",
    "contr_reps_train_5d_att01_sgd, contr_reps_test_5d_att01_sgd, contr_reps_test_5d_pca_att01_sgd, _, _ = \\\n",
    "    get_ckpt_results(fived_norm_attenc01_sgd_path, 5, dy_wfs_interest, dy_wfs_test, True, dy_wfs, wf_interest_dy, \\\n",
    "                     '5D contrastive model (augs=a/j/n, transformer, lr=0.01, sgd) (2D PCA reps) - test set', \\\n",
    "                     enc_type='attention_encoder', \\\n",
    "                     save_name='pca_v_5dcont_normal_attenc_lr01_sgd')\n",
    "contr_reps_train_5d_att01_sgdfc4, contr_reps_test_5d_att01_sgdfc4, contr_reps_test_5d_pca_att01_sgdfc4, _, _ = \\\n",
    "    get_ckpt_results(fived_norm_attenc01_sgdfc4_path, 5, dy_wfs_interest, dy_wfs_test, True, dy_wfs, wf_interest_dy, \\\n",
    "                     '5D contrastive model (augs=a/j/n, transformer, lr=0.01, sgd, fc4) (2D PCA reps) - test set', \\\n",
    "                     enc_type='attention_encoder', fc=4, \\\n",
    "                     save_name='pca_v_5dcont_normal_attenc_lr01_sgdfc4')\n",
    "contr_reps_train_5d_att001_sgd, contr_reps_test_5d_att001_sgd, contr_reps_test_5d_pca_att001_sgd, _, _ = \\\n",
    "    get_ckpt_results(fived_norm_attenc001_sgd_path, 5, dy_wfs_interest, dy_wfs_test, True, dy_wfs, wf_interest_dy, \\\n",
    "                     '5D contrastive model (augs=a/j/n, transformer, lr=0.001, sgd) (2D PCA reps) - test set', \\\n",
    "                     enc_type='attention_encoder', \\\n",
    "                     save_name='pca_v_5dcont_normal_attenc_lr001_sgd')\n",
    "contr_reps_train_5d_att001_sgdfc4, contr_reps_test_5d_att001_sgdfc4, contr_reps_test_5d_pca_att001_sgdfc4, _, _ = \\\n",
    "    get_ckpt_results(fived_norm_attenc001_sgdfc4_path, 5, dy_wfs_interest, dy_wfs_test, True, dy_wfs, wf_interest_dy, \\\n",
    "                     '5D contrastive model (augs=a/j/n, transformer, lr=0.001, sgd, fc4) (2D PCA reps) - test set', \\\n",
    "                     enc_type='attention_encoder', fc=4, save_name='pca_v_5dcont_normal_attenc_lr001_sgdfc4')\n",
    "\n",
    "\n",
    "train_reps = [pca_train_5d, \n",
    "              contr_reps_train_5d_att001, contr_reps_train_5d_att0001_fc4, contr_reps_train_5d_att0001, \n",
    "              contr_reps_train_5d_att01_sgd, contr_reps_train_5d_att01_sgdfc4, contr_reps_train_5d_att001_sgd,\n",
    "              contr_reps_train_5d_att001_sgdfc4]\n",
    "test_reps = [pca_test_5d,  \n",
    "              contr_reps_test_5d_att001, contr_reps_test_5d_att0001_fc4, contr_reps_test_5d_att0001, \n",
    "              contr_reps_test_5d_att01_sgd, contr_reps_test_5d_att01_sgdfc4, contr_reps_test_5d_att001_sgd,\n",
    "              contr_reps_test_5d_att001_sgdfc4]\n",
    "model_names = ['PCA 5D',  \n",
    "          'Contrastive 5D (augs=a/j/n, transformer, lr=0.001)', 'Contrastive 5D (augs=a/j/n, transformer, lr=0.0001, fc4)',\n",
    "          'Contrastive 5D (augs=a/j/n, transformer, lr=0.0001)', 'Contrastive 5D (augs=a/j/n, transformer, lr=0.01, sgd)', \n",
    "          'Contrastive 5D (augs=a/j/n, transformer, lr=0.01, sgd, fc4)', 'Contrastive 5D (augs=a/j/n, transformer, lr=0.001, sgd)',\n",
    "          'Contrastive 5D (augs=a/j/n, transformer, lr=0.001, sgd, fc4)']\n",
    "\n",
    "\n",
    "per_class_map = per_class_accs(train_reps, test_reps, model_names, 10)\n",
    "avg_class_map = avg_class_accs(train_reps, test_reps, model_names, 10)\n",
    "\n",
    "pc_df = pd.DataFrame.from_dict(per_class_map, 'index')\n",
    "ac_df = pd.DataFrame.from_dict(avg_class_map)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(pc_df)\n",
    "    \n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(ac_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
